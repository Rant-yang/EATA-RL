import numpy as np
import pandas as pd
import torch
from typing import Optional, Dict, Any, List, Tuple
from scipy.stats import entropy

# å¯¼å…¥æ–°çš„NEMoTSæ ¸å¿ƒæ¨¡å—
from eata_agent.engine import Engine
from eata_agent.args import Args

class Agent:
    def __init__(self, df: pd.DataFrame, lookback: int = 100, lookahead: int = 20):
        self.stock_list = df
        self.lookback = lookback
        self.lookahead = lookahead
        self.hyperparams = self._create_hyperparams()
        self.engine = Engine(self.hyperparams)
        self.previous_best_tree = None
        self.previous_best_expression = None
        self.is_trained = False
        self.training_history = []
        self.__name__ = 'EATA_Agent_v3.1_fixed_strategy'

        print("EATA Agent (å›ºå®šç­–ç•¥æ¨¡å¼) åˆå§‹åŒ–å®Œæˆ")
        print(f"   - Lookback={self.lookback}, Lookahead={self.lookahead}")
        print("   - å†³ç­–è§„åˆ™: å›ºå®š Q25/Q75 å…±è¯†è§„åˆ™")

    def _create_hyperparams(self) -> Args:
        """åˆ›å»ºè¶…å‚æ•°é…ç½® - å¢å¼ºç‰ˆ"""
        args = Args()
        args.device = torch.device("cpu")
        args.seed = 42
        args.seq_in = self.lookback
        args.seq_out = self.lookahead
        args.used_dimension = 1
        args.features = 'M'
        args.symbolic_lib = "NEMoTS"
        args.max_len = 35
        args.max_module_init = 10
        args.num_transplant = 5
        args.num_runs = 5
        args.eta = 1.0
        args.num_aug = 3
        args.exploration_rate = 1 / np.sqrt(2)
        args.transplant_step = 800
        args.norm_threshold = 1e-5
        args.epoch = 10
        args.round = 2
        args.train_size = 64
        args.lr = 1e-5
        args.weight_decay = 0.0001
        args.clip = 5.0
        args.buffer_size = 64
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        return args

    def _prepare_data(self, df: pd.DataFrame) -> np.ndarray:
        """å‡†å¤‡å•ä¸ªæ»‘åŠ¨çª—å£çš„æ•°æ®"""
        feature_cols = ['open', 'high', 'low', 'close', 'volume', 'amount']
        if not all(col in df.columns for col in feature_cols):
            raise ValueError(f"è¾“å…¥æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: éœ€è¦ {feature_cols}")
        
        data = df[feature_cols].values
        diff = np.diff(data, axis=0)
        last_row = data[:-1]
        last_row[last_row == 0] = 1e-9
        change_rates = diff / last_row
        
        change_rates[:, :4] = np.clip(change_rates[:, :4], -0.1, 0.1)
        change_rates[:, 4:] = np.clip(change_rates[:, 4:], -0.5, 0.5)

        if len(change_rates) < self.lookback + self.lookahead:
            raise ValueError(f"æ•°æ®é•¿åº¦ä¸è¶³ï¼šéœ€è¦{self.lookback + self.lookahead}ï¼Œå®é™…å¯ç”¨{len(change_rates)}")
        
        window_data = change_rates[-(self.lookback + self.lookahead):]
        return window_data

    def _predict_distribution(self, top_10_exps: List[str], lookback_data: np.ndarray) -> np.ndarray:
        """ä¸ºTop-10è¡¨è¾¾å¼ç”Ÿæˆæœªæ¥é¢„æµ‹åˆ†å¸ƒ"""
        all_predictions = []
        lookback_data_transposed = lookback_data.T

        eval_vars = {"np": np}
        for i in range(lookback_data_transposed.shape[0]):
            eval_vars[f'x{i}'] = lookback_data_transposed[i, :]

        for exp in top_10_exps:
            try:
                corrected_expression = exp.replace("exp", "np.exp").replace("cos", "np.cos").replace("sin", "np.sin").replace("sqrt", "np.sqrt").replace("log", "np.log")
                historical_fit = eval(corrected_expression, {"__builtins__": None}, eval_vars)

                if not isinstance(historical_fit, np.ndarray) or historical_fit.ndim == 0:
                    historical_fit = np.repeat(historical_fit, self.lookback)
                
                time_axis = np.arange(self.lookback)
                coeffs = np.polyfit(time_axis, historical_fit, 1)
                trend_line = np.poly1d(coeffs)

                future_time_axis = np.arange(self.lookback, self.lookback + self.lookahead)
                future_predictions = trend_line(future_time_axis)
                all_predictions.extend(future_predictions)

            except Exception as e:
                print(f"è¡¨è¾¾å¼ '{exp}' é¢„æµ‹å¤±è´¥: {e}ã€‚å°†å¡«å……0ã€‚")
                all_predictions.extend([0] * self.lookahead)
        
        return np.array(all_predictions)

    def _calculate_rl_reward_and_signal(self, prediction_distribution: np.ndarray, lookahead_ground_truth: np.ndarray, shares_held: int) -> Tuple[float, int]:
        """
        è®¡ç®—RLå¥–åŠ±å’Œäº¤æ˜“ä¿¡å·
        - RLå¥–åŠ±: åŸºäºé¢„æµ‹åˆ†å¸ƒä¸çœŸå®åˆ†å¸ƒçš„KLæ•£åº¦(Kullback-Leibler Divergence)ã€‚
        - äº¤æ˜“ä¿¡å·: åŸºäºå›ºå®šçš„Q25/Q75è§„åˆ™ã€‚
        """
        try:
            if prediction_distribution.size == 0:
                return 0.0, 0

            # --- äº¤æ˜“ä¿¡å·å†³ç­– (é€»è¾‘ä¿æŒä¸å˜) ---
            strategy = [25, 75]
            q_low, q_high = np.percentile(prediction_distribution, strategy)
            intended_signal = 0
            if q_low > 0:
                intended_signal = 1
                print(f"  [å†³ç­–] é¢„æµ‹åˆ†å¸ƒçš„ 25% åˆ†ä½æ•° > 0ï¼Œç”Ÿæˆæ„å›¾ä¿¡å·: ä¹°å…¥")
            elif q_high < 0:
                intended_signal = -1
                print(f"  [å†³ç­–] é¢„æµ‹åˆ†å¸ƒçš„ 75% åˆ†ä½æ•° < 0ï¼Œç”Ÿæˆæ„å›¾ä¿¡å·: å–å‡º")
            else:
                print("  [å†³ç­–] é¢„æµ‹åˆ†å¸ƒè·¨è¶Šé›¶ç‚¹ï¼Œä¿¡å·ä¸æ˜ç¡®ï¼Œç”Ÿæˆæ„å›¾ä¿¡å·: æŒæœ‰")

            # --- RLå¥–åŠ±è®¡ç®— (æ–°é€»è¾‘: KLæ•£åº¦) ---
            # 1. æå–çœŸå®çš„æ—¥æ”¶ç›Šç‡
            actual_returns = lookahead_ground_truth.T[3, :] 

            # 2. ä¸ºä¸¤ä¸ªåˆ†å¸ƒåˆ›å»ºå…±åŒçš„åŒºé—´(bins)
            combined_data = np.concatenate((prediction_distribution, actual_returns))
            min_val, max_val = np.min(combined_data), np.max(combined_data)
            num_bins = 50  # å®šä¹‰åˆ†ç®±æ•°é‡
            bins = np.linspace(min_val, max_val, num_bins)

            # 3. è®¡ç®—ä¸¤ä¸ªåˆ†å¸ƒåœ¨å…±åŒåŒºé—´ä¸Šçš„ç›´æ–¹å›¾
            pred_hist, _ = np.histogram(prediction_distribution, bins=bins, density=True)
            actual_hist, _ = np.histogram(actual_returns, bins=bins, density=True)

            # 4. å°†é¢‘ç‡è½¬æ¢ä¸ºæ¦‚ç‡ï¼Œå¹¶æ·»åŠ å¹³æ»‘é¡¹é˜²æ­¢log(0)
            epsilon = 1e-10
            pred_probs = pred_hist / np.sum(pred_hist) + epsilon
            actual_probs = actual_hist / np.sum(actual_hist) + epsilon

            # 5. è®¡ç®—KLæ•£åº¦
            # scipy.stats.entropy(pk, qk) è®¡ç®— pk ç›¸å¯¹äº qk çš„KLæ•£åº¦
            kl_divergence = entropy(pred_probs, actual_probs)

            # 6. å°†KLæ•£åº¦è½¬æ¢ä¸ºå¥–åŠ±
            rl_reward = 1 / (1 + kl_divergence)
            
            return rl_reward, intended_signal
        except Exception as e:
            print(f"--- ğŸš¨ åœ¨ _calculate_rl_reward_and_signal ä¸­æ•è·åˆ°è‡´å‘½é”™è¯¯ ğŸš¨ ---")
            print(f"é”™è¯¯ä¿¡æ¯: {e}")
            import traceback
            traceback.print_exc()
            print(f"--- è¯Šæ–­ç»“æŸ ---")
            return 0.0, 0

    def criteria(self, d: pd.DataFrame, shares_held: int) -> int:
        """æ ¸å¿ƒå†³ç­–å‡½æ•°ï¼Œé›†æˆç­–ç•¥å­¦ä¹ æµç¨‹"""
        try:
            if self.previous_best_tree is not None:
                print("æ£€æµ‹åˆ°å·²æœ‰è¯­æ³•æ ‘ï¼Œåˆ‡æ¢åˆ°çƒ­å¯åŠ¨å‚æ•° (num_runs=1)...")
                self.engine.model.num_runs = 1 # æ ¸å¿ƒä¼˜åŒ–ï¼šçƒ­å¯åŠ¨æ—¶ï¼Œåªè¿è¡Œ1æ¬¡MCTS
                self.engine.model.num_transplant = 5
                self.engine.model.transplant_step = 300
                self.engine.model.num_aug = 3
            else:
                print("é¦–æ¬¡è¿è¡Œï¼Œä½¿ç”¨é‡é‡çº§å‚æ•°...")
                # ä½¿ç”¨æ›´å¼ºçš„å†·å¯åŠ¨å‚æ•°
                self.engine.model.num_runs = 5
                self.engine.model.max_len = 35

            full_window_data = self._prepare_data(d)
            lookback_data = full_window_data[:self.lookback, :]
            lookahead_data = full_window_data[-self.lookahead:, :]

            # engine.simulate ç°åœ¨è¿”å› mcts_records
            best_exp, top_10_exps, top_10_scores, _, mae, mse, corr, _, mcts_score, new_best_tree, mcts_records = self.engine.simulate(
                full_window_data, previous_best_tree=self.previous_best_tree
            )

            self.previous_best_expression = str(best_exp)
            self.previous_best_tree = new_best_tree
            self.is_trained = True
            
            record = {'mae': mae, 'corr': corr, 'mcts_score': mcts_score}
            self.training_history.append(record)
            print(f"NEMoTSè¿è¡Œå®Œæˆ: MAE={mae:.4f}, Corr={corr:.4f}, MCTS Score={mcts_score:.4f}")

            prediction_distribution = self._predict_distribution(top_10_exps, lookback_data)
            print(f"ç”Ÿæˆäº† {len(prediction_distribution)} ä¸ªé¢„æµ‹ç‚¹ã€‚")

            rl_reward, trading_signal = self._calculate_rl_reward_and_signal(
                prediction_distribution, lookahead_data, shares_held
            )
            print(f"RLå¥–åŠ± (åŸºäºçœŸå®ä¿¡å·): {rl_reward:.4f}, æ„å›¾äº¤æ˜“ä¿¡å·: {trading_signal}")

            # â€œç›–æˆ³â€æµç¨‹ï¼šå°†æœ€ç»ˆçš„rl_rewardé™„åŠ åˆ°æœ¬æ¬¡çª—å£äº§ç”Ÿçš„æ‰€æœ‰ç»éªŒä¸Š
            stamped_experiences = []
            for experience in mcts_records:
                # experience æ˜¯ä¸€ä¸ªå…ƒç»„ (state, seq, policy, value)
                stamped_experience = experience + (rl_reward,)
                stamped_experiences.append(stamped_experience)
            
            # å°†â€œç›–æˆ³â€åçš„ç»éªŒæ•°æ®å­˜å…¥å¼•æ“ï¼Œå¹¶ç”±å¼•æ“å†³å®šæ˜¯å¦è§¦å‘è®­ç»ƒ
            if stamped_experiences:
                self.engine.store_experiences(stamped_experiences)

            return trading_signal, rl_reward

        except Exception as e:
            print(f"NEMoTS Agent 'criteria' å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0

    # choose_action, vote, strength æ–¹æ³•ä¿æŒä¸å˜
    @classmethod
    def choose_action(cls, s: tuple) -> int:
        try:
            _, s1, _, _ = s
            temp_agent = Agent(pd.DataFrame())
            # æ³¨æ„ï¼šè¿™é‡Œçš„é™æ€è°ƒç”¨æ— æ³•çŸ¥é“æŒä»“çŠ¶æ€ï¼Œè¿™æ˜¯ä¸€ä¸ªç®€åŒ–å¤„ç†ã€‚
            # åœ¨çœŸå®çš„å¤šè‚¡ç¥¨åœºæ™¯ä¸­ï¼Œéœ€è¦ä¸ºæ¯ä¸ªè‚¡ç¥¨ç»´æŠ¤ä¸€ä¸ªAgentå®ä¾‹ã€‚
            return temp_agent.criteria(s1, shares_held=0) # å‡è®¾é»˜è®¤æ˜¯ç©ºä»“
        except Exception as e:
            print(f"åŠ¨ä½œé€‰æ‹©å¤±è´¥: {e}")
            return 0

    def vote(self) -> int:
        print("'vote' æ–¹æ³•è¢«ç®€åŒ–ï¼Œä»…è¿”å›ä¸­æ€§ä¿¡å·ã€‚è¯·åœ¨ predict.py ä¸­å®ç°å¤šè‚¡ç¥¨å¾ªç¯ã€‚")
        return 50

    def strength(self, w1: float, w2: float, w3: float, w4: float) -> pd.Series:
        print("'strength' æ–¹æ³•è¢«ç®€åŒ–ï¼Œè¿”å›å›ºå®šå€¼ã€‚")
        self.stock_list['strength'] = [50] * len(self.stock_list)
        return self.stock_list['strength']
